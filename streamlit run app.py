import streamlit as st
import pandas as pd
import io
import zipfile # ZIP ‡§´‡§º‡§æ‡§á‡§≤ ‡§ï‡•ã ‡§π‡•à‡§Ç‡§°‡§≤ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è

# --- ‡§´‡§º‡§Ç‡§ï‡•ç‡§∂‡§®: ZIP ‡§´‡§º‡§æ‡§á‡§≤ ‡§π‡•à‡§Ç‡§°‡§≤‡§ø‡§Ç‡§ó ---
def handle_zip_upload(zip_file):
    """
    ZIP ‡§´‡§º‡§æ‡§á‡§≤ ‡§ï‡•ã ‡§è‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡•à‡§ï‡•ç‡§ü ‡§ï‡§∞‡§§‡§æ ‡§π‡•à ‡§î‡§∞ Packed, RT.., RTO.csv ‡§ï‡•ã StringIO ‡§ë‡§¨‡•ç‡§ú‡•á‡§ï‡•ç‡§ü ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§µ‡§æ‡§™‡§∏ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§
    """
    if zip_file is None:
        return None, None, None, False

    csv_data = {}
    required_files = ["Packed.csv", "RT..csv", "RTO.csv"]
    
    st.info("Extracting files from the ZIP archive...")

    try:
        with zipfile.ZipFile(zip_file, 'r') as z:
            for file_name in required_files:
                # ZIP ‡§Æ‡•á‡§Ç ‡§´‡§º‡§æ‡§á‡§≤ ‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§ï‡•á‡§∏-‡§∏‡•á‡§Ç‡§∏‡§ø‡§ü‡§ø‡§µ ‡§π‡•ã ‡§∏‡§ï‡§§‡§æ ‡§π‡•à, ‡§á‡§∏‡§≤‡§ø‡§è exact match ‡§ú‡§º‡§∞‡•Ç‡§∞‡•Ä ‡§π‡•à
                if file_name in z.namelist():
                    # ‡§´‡§º‡§æ‡§á‡§≤ ‡§ï‡•Ä ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä ‡§ï‡•ã ‡§™‡§¢‡§º‡•á‡§Ç ‡§î‡§∞ utf-8 ‡§Æ‡•á‡§Ç ‡§°‡§ø‡§ï‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç
                    file_content = z.read(file_name).decode('utf-8')
                    # StringIO ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§á‡§∏‡•á Pandas ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§´‡§º‡§æ‡§á‡§≤ ‡§ë‡§¨‡•ç‡§ú‡•á‡§ï‡•ç‡§ü ‡§ï‡•Ä ‡§§‡§∞‡§π ‡§¨‡§®‡§æ‡§è‡§Ç
                    csv_data[file_name] = io.StringIO(file_content)
                else:
                    st.error(f"Required file **{file_name}** not found in the ZIP archive.")
                    return None, None, None, False
        
        # StringIO ‡§ë‡§¨‡•ç‡§ú‡•á‡§ï‡•ç‡§ü‡•ç‡§∏ ‡§ï‡•ã ‡§Ö‡§™‡•á‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ï‡•ç‡§∞‡§Æ ‡§Æ‡•á‡§Ç ‡§µ‡§æ‡§™‡§∏ ‡§ï‡§∞‡•á‡§Ç
        return csv_data.get("Packed.csv"), csv_data.get("RT..csv"), csv_data.get("RTO.csv"), True
    
    except zipfile.BadZipFile:
        st.error("Invalid ZIP file uploaded. Please upload a valid .zip archive.")
        return None, None, None, False
    except Exception as e:
        st.error(f"An error occurred during ZIP file extraction: {e}")
        return None, None, None, False

# --- ‡§´‡§º‡§Ç‡§ï‡•ç‡§∂‡§®: ‡§°‡•á‡§ü‡§æ ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§ø‡§Ç‡§ó (‡§ï‡•ã‡§∞ ‡§≤‡•â‡§ú‡§ø‡§ï ‡§µ‡§π‡•Ä ‡§π‡•à) ---
def process_data(packed_file_obj, rt_file_obj, rto_file_obj, seller_listings_file):
    """
    ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡•Ä ‡§ó‡§à ‡§´‡§º‡§æ‡§á‡§≤‡•ã‡§Ç ‡§ï‡•ã ‡§™‡§¢‡§º‡§§‡§æ ‡§π‡•à, SKU ID ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞ SKU Code ‡§î‡§∞ Seller SKU Code ‡§ï‡•ã ‡§Æ‡§∞‡•ç‡§ú ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§
    """
    
    # 1. Seller Listings File ‡§∏‡•á ‡§Æ‡•à‡§™‡§ø‡§Ç‡§ó ‡§°‡•á‡§ü‡§æ ‡§®‡§ø‡§ï‡§æ‡§≤‡•á‡§Ç
    try:
        seller_df = pd.read_csv(seller_listings_file, engine='python')
        
        # ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§ï‡•â‡§≤‡§Æ ‡§ï‡•ã ‡§ö‡•Å‡§®‡•á‡§Ç ‡§î‡§∞ ‡§ï‡•â‡§≤‡§Æ ‡§ï‡•á ‡§®‡§æ‡§Æ Normalize ‡§ï‡§∞‡•á‡§Ç
        sku_map_df = seller_df[['sku id', 'sku code', 'seller sku code']].copy()
        sku_map_df.columns = sku_map_df.columns.str.strip().str.replace('"', '').str.replace(' ', '_')
        sku_map_df.rename(columns={
            'sku_id': 'sku_id', 
            'sku_code': 'sku_code',
            'seller_sku_code': 'seller_sku_code'
        }, inplace=True)
        
        sku_map_df.drop_duplicates(subset=['sku_id'], inplace=True)
        sku_map_df['sku_id'] = sku_map_df['sku_id'].astype(str) # Data type normalization
        
    except Exception as e:
        st.error(f"Seller Listings Report ‡§™‡§¢‡§º‡§®‡•á ‡§Æ‡•á‡§Ç ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø ‡§Ø‡§æ ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§ï‡•â‡§≤‡§Æ ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡•á: {e}")
        return None, None, None

    # ‡§°‡•á‡§ü‡§æ‡§´‡§º‡•ç‡§∞‡•á‡§Æ ‡§ï‡•Ä ‡§∏‡•Ç‡§ö‡•Ä ‡§¨‡§®‡§æ‡§è‡§Ç
    file_list = [
        ("Packed.csv", packed_file_obj, 'packed_df'),
        ("RT..csv", rt_file_obj, 'rt_df'),
        ("RTO.csv", rto_file_obj, 'rto_df')
    ]
    
    processed_dfs = {}

    for file_name, file_obj, df_key in file_list:
        if file_obj is not None:
            st.info(f"Merging data for {file_name}...")
            try:
                # StringIO ‡§ë‡§¨‡•ç‡§ú‡•á‡§ï‡•ç‡§ü ‡§∏‡•á ‡§°‡•á‡§ü‡§æ ‡§™‡§¢‡§º‡•á‡§Ç
                df = pd.read_csv(file_obj)
                
                merge_column = None
                original_sku_id_name = None
                
                if 'sku_id' in df.columns:
                    merge_column = 'sku_id'
                    original_sku_id_name = 'sku_id'
                elif 'sku id' in df.columns:
                    original_sku_id_name = 'sku id'
                    df.rename(columns={'sku id': 'sku_id'}, inplace=True)
                    merge_column = 'sku_id'
                
                if merge_column is None:
                    st.warning(f"File **{file_name}** does not contain a suitable 'sku id' column. Data not merged.")
                    processed_dfs[df_key] = df
                    continue

                # 'sku_id' ‡§ï‡•â‡§≤‡§Æ ‡§ï‡•ã string ‡§Æ‡•á‡§Ç ‡§¨‡§¶‡§≤‡•á‡§Ç ‡§§‡§æ‡§ï‡§ø merging ‡§†‡•Ä‡§ï ‡§∏‡•á ‡§π‡•ã
                df[merge_column] = df[merge_column].astype(str)
                
                # 'sku_id' ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞ ‡§Æ‡§∞‡•ç‡§ú ‡§ï‡§∞‡•á‡§Ç
                merged_df = pd.merge(df, sku_map_df, on=merge_column, how='left')
                
                # 'Not Found' ‡§∏‡•á ‡§Æ‡§ø‡§∏‡§ø‡§Ç‡§ó values ‡§≠‡§∞‡•á‡§Ç
                merged_df['seller_sku_code'] = merged_df['seller_sku_code'].fillna('Not Found')
                merged_df['sku_code'] = merged_df['sku_code'].fillna('Not Found')

                # ‡§ï‡•â‡§≤‡§Æ ‡§ï‡•ã 'sku_id' ‡§ï‡•á ‡§Ü‡§ó‡•á Insert ‡§ï‡§∞‡•á‡§Ç
                sku_id_index = merged_df.columns.get_loc('sku_id')
                
                seller_sku_col = merged_df.pop('seller_sku_code')
                sku_code_col = merged_df.pop('sku_code')
                
                # 'seller_sku_code' ‡§ï‡•ã 'sku_id' ‡§ï‡•á ‡§†‡•Ä‡§ï ‡§Ü‡§ó‡•á Insert ‡§ï‡§∞‡•á‡§Ç
                merged_df.insert(sku_id_index + 1, 'seller_sku_code', seller_sku_col)
                
                # 'sku_code' ‡§ï‡•ã 'seller_sku_code' ‡§ï‡•á ‡§†‡•Ä‡§ï ‡§Ü‡§ó‡•á Insert ‡§ï‡§∞‡•á‡§Ç
                merged_df.insert(sku_id_index + 2, 'sku_code', sku_code_col)

                # ‡§Ø‡§¶‡§ø ‡§Æ‡•Ç‡§≤ 'sku id' ‡§ï‡•â‡§≤‡§Æ ‡§ï‡§æ ‡§®‡§æ‡§Æ 'sku id' ‡§•‡§æ, ‡§§‡•ã ‡§â‡§∏‡•á ‡§µ‡§æ‡§™‡§∏ ‡§†‡•Ä‡§ï ‡§ï‡§∞‡•á‡§Ç
                if original_sku_id_name == 'sku id':
                    merged_df.rename(columns={'sku_id': 'sku id'}, inplace=True)
                
                processed_dfs[df_key] = merged_df
                st.success(f"**{file_name}** successfully processed.")

            except Exception as e:
                st.error(f"Error reading or processing **{file_name}**: {e}")
                processed_dfs[df_key] = None
        else:
            processed_dfs[df_key] = None
    
    return processed_dfs.get('packed_df'), processed_dfs.get('rt_df'), processed_dfs.get('rto_df')

# --- ‡§´‡§º‡§Ç‡§ï‡•ç‡§∂‡§®: ‡§Æ‡§≤‡•ç‡§ü‡•Ä-‡§∂‡•Ä‡§ü Excel ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§°‡§∞ ---
def convert_dfs_to_excel(df_packed, df_rt, df_rto):
    """
    ‡§§‡•Ä‡§® DataFrames ‡§ï‡•ã ‡§è‡§ï Excel ‡§´‡§º‡§æ‡§á‡§≤ ‡§ï‡•Ä ‡§Ö‡§≤‡§ó-‡§Ö‡§≤‡§ó ‡§∂‡•Ä‡§ü‡•ç‡§∏ ‡§Æ‡•á‡§Ç ‡§≤‡§ø‡§ñ‡§§‡§æ ‡§π‡•à‡•§
    """
    output = io.BytesIO()
    
    # Pandas ExcelWriter ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á BytesIO ‡§ë‡§¨‡•ç‡§ú‡•á‡§ï‡•ç‡§ü ‡§Æ‡•á‡§Ç ‡§≤‡§ø‡§ñ‡•á‡§Ç
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        if df_packed is not None:
            df_packed.to_excel(writer, sheet_name='Packed', index=False)
        if df_rt is not None:
            df_rt.to_excel(writer, sheet_name='RT', index=False)
        if df_rto is not None:
            df_rto.to_excel(writer, sheet_name='RTO', index=False)
    
    # BytesIO ‡§∏‡•á ‡§¨‡§æ‡§á‡§ü‡•ç‡§∏ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡•á‡§Ç
    processed_excel_data = output.getvalue()
    return processed_excel_data

# --- Streamlit ‡§°‡•à‡§∂‡§¨‡•ã‡§∞‡•ç‡§° ‡§≤‡•á‡§Ü‡§â‡§ü ---
def main():
    st.set_page_config(
        page_title="SKU Data Merger & Excel Generator",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("üõçÔ∏è SKU Data Merger & Excel Generator")
    st.markdown("---")
    
    st.sidebar.header("üìÅ Upload Your Files")
    
    # ‡§´‡§º‡§æ‡§á‡§≤ ‡§Ö‡§™‡§≤‡•ã‡§°‡§∞‡•ç‡§∏
    # 1. Seller Listings Report (CSV)
    seller_listings_file = st.sidebar.file_uploader(
        "Upload **Seller Listings Report.csv** (Required)", 
        type=['csv'],
        key="seller"
    )
    
    # 2. Packed, RT, RTO ZIP file
    data_zip_file = st.sidebar.file_uploader(
        "Upload **Packed, RT, RTO files as a ZIP** (e.g., Data.zip)", 
        type=['zip'],
        key="data_zip"
    )
    
    st.markdown("---")
    
    if st.sidebar.button("üöÄ Start Processing & Generate Excel"):
        if seller_listings_file is None or data_zip_file is None:
            st.error("Please upload both the **Seller Listings Report.csv** and the **Data ZIP file** to start the process.")
        else:
            # 1. ZIP ‡§´‡§º‡§æ‡§á‡§≤ ‡§ï‡•ã ‡§π‡•à‡§Ç‡§°‡§≤ ‡§ï‡§∞‡•á‡§Ç
            packed_obj, rt_obj, rto_obj, success = handle_zip_upload(data_zip_file)
            
            if success:
                # 2. ‡§°‡•á‡§ü‡§æ ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§ø‡§Ç‡§ó
                with st.spinner("Merging SKU data and generating Excel workbook... Please wait."):
                    packed_df_merged, rt_df_merged, rto_df_merged = process_data(
                        packed_obj, rt_obj, rto_obj, seller_listings_file
                    )

                st.header("‚úÖ Processing Complete")
                
                # ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç ‡§ï‡§ø ‡§ï‡§Æ ‡§∏‡•á ‡§ï‡§Æ ‡§è‡§ï ‡§´‡§º‡§æ‡§á‡§≤ ‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏ ‡§π‡•Å‡§à ‡§π‡•à
                if packed_df_merged is not None or rt_df_merged is not None or rto_df_merged is not None:
                    # 3. Excel ‡§´‡§º‡§æ‡§á‡§≤ ‡§ú‡§®‡§∞‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç
                    excel_data = convert_dfs_to_excel(packed_df_merged, rt_df_merged, rto_df_merged)
                    
                    st.success("Your multi-sheet Excel file is ready for download.")
                    
                    # 4. ‡§∏‡§ø‡§Ç‡§ó‡§≤ Excel ‡§´‡§º‡§æ‡§á‡§≤ ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§° ‡§¨‡§ü‡§®
                    st.download_button(
                        label="‚¨áÔ∏è Download Merged Data (Excel)",
                        data=excel_data,
                        file_name='Merged_SKU_Report.xlsx',
                        mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                        key='download_excel'
                    )
                    
                    st.markdown("---")
                    st.subheader("Preview (First 5 Rows of Packed Data)")
                    if packed_df_merged is not None:
                         st.dataframe(packed_df_merged.head())
                    else:
                        st.info("Packed data was not processed successfully to show preview.")
                        
                else:
                    st.error("No data files were successfully processed. Please check file names inside the ZIP (Packed.csv, RT..csv, RTO.csv) and the columns in the Seller Listings Report.")

# Streamlit App ‡§ï‡•ã ‡§∞‡§® ‡§ï‡§∞‡•á‡§Ç
if __name__ == "__main__":
    main()
